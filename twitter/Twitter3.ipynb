{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import emoji\n",
    "import tweepy\n",
    "from janome.tokenizer import Tokenizer\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter, defaultdict\n",
    "from requests_oauthlib import OAuth1Session\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"my consumer_key\"\n",
    "consumer_secret = \"my consumer_secret\"\n",
    "access_token = \"my access_token\"\n",
    "access_token_secret = \"my access_token_secret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = OAuth1Session(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_url = \"https://api.twitter.com/1.1/statuses/user_timeline.json\"\n",
    "tweet_url = \"https://api.twitter.com/1.1/search/tweets.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'screen_name': '@g031p068siwate1',\n",
    "          'exclude_replies': True,\n",
    "          'include_rts': False,\n",
    "          'count': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(src_str):\n",
    "    return ''.join(c for c in src_str if c not in emoji.UNICODE_EMOJI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(texts):\n",
    "    t = Tokenizer(\"dic.csv\",udic_type=\"simpledic\", udic_enc=\"shift-jis\")\n",
    "    words_count = defaultdict(int)\n",
    "    words = []\n",
    "    for text in texts:\n",
    "        tokens = t.tokenize(text)\n",
    "        for token in tokens:\n",
    "            # 品詞から名詞だけ抽出\n",
    "            pos = token.part_of_speech.split(',')[0]\n",
    "            if pos in ['名詞']:\n",
    "                # 必要ない単語を省く(実際の結果を見てから不必要そうな単語を記載しました)\n",
    "                if token.base_form not in [\"こと\", \"よう\", \"そう\", \"これ\", \"それ\"]:\n",
    "                    words_count[token.base_form] += 1\n",
    "                    words.append(token.base_form)\n",
    "    return words_count, words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自分のツイートを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = open('tweet.txt', 'w')\n",
    "\n",
    "for j in range(100):\n",
    "    res = twitter.get(timeline_url, params=params)\n",
    "    if res.status_code == 200:\n",
    "        # API残り回数\n",
    "        limit = res.headers['x-rate-limit-remaining']\n",
    "        #print(\"API remain: \" + limit)\n",
    "        if limit == 1:\n",
    "            sleep(60*15)\n",
    "\n",
    "        n = 0\n",
    "        timeline = json.loads(res.text)\n",
    "        # 各ツイートの本文を表示\n",
    "        for i in range(len(timeline)):\n",
    "            if i != len(timeline)-1:# 絵文字があると、wordcloudが使用できないため、削除する\n",
    "                f_out.write(remove_emoji(timeline[i]['text']) + '\\n')\n",
    "            else:# 絵文字があると、wordcloudが使用できないため、削除する\n",
    "                f_out.write(remove_emoji(timeline[i]['text']) + '\\n')\n",
    "                # 一番最後のツイートIDをパラメータmax_idに追加\n",
    "                params['max_id'] = timeline[i]['id']-1\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力されたキーワードのツイートを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "何を調べますか?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  マクドナルド\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "f_out = open('keyword.txt', 'w')\n",
    "\n",
    "print(\"何を調べますか?\")\n",
    "keyword = input('>> ')\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "params = {'q' : keyword, 'count' : 50}\n",
    "req = twitter.get(tweet_url, params = params)\n",
    "if req.status_code == 200:\n",
    "    public_tweets = api.home_timeline()\n",
    "    for tweet in public_tweets:\n",
    "            f_out.write(remove_emoji(tweet.text).replace('\\ufe0f','').replace('\\xa5','') + '\\n')\n",
    "else:\n",
    "    print(\"ERROR: %d\" % req.status_code)\n",
    "\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    #DancingMen-SherlockHolmes-Japanese.txt\n",
    "    texts = []\n",
    "    for row in reader:\n",
    "        if(len(row) > 0):\n",
    "            text = row[0].split('http')\n",
    "            texts.append(text[0])\n",
    "\n",
    "words_count, words = counter(texts)\n",
    "text = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fontは自分の端末にあるものを使用する\n",
    "fpath = r\"C:\\home\\Fonts\\RictyDiminished-for-Powerline-master\\RictyDiminished-Bold.ttf\"\n",
    "wordcloud = WordCloud(background_color=\"white\",font_path=fpath, width=900, height=500).generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x30e9d5d0f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud.to_file(\"./wordcloud_tweet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keyword.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    #DancingMen-SherlockHolmes-Japanese.txt\n",
    "    texts = []\n",
    "    for row in reader:\n",
    "        if(len(row) > 0):\n",
    "            text = row[0].split('http')\n",
    "            texts.append(text[0])\n",
    "\n",
    "words_count, words = counter(texts)\n",
    "text = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fontは自分の端末にあるものを使用する\n",
    "fpath = r\"C:\\home\\Fonts\\RictyDiminished-for-Powerline-master\\RictyDiminished-Bold.ttf\"\n",
    "wordcloud = WordCloud(background_color=\"white\",font_path=fpath, width=900, height=500).generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x30e9fb3ef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud.to_file(\"./wordcloud_keyword.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DancingMen-SherlockHolmes-Japanese.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    #DancingMen-SherlockHolmes-Japanese.txt\n",
    "    texts = []\n",
    "    for row in reader:\n",
    "        if(len(row) > 0):\n",
    "            text = row[0].split('http')\n",
    "            texts.append(text[0])\n",
    "\n",
    "words_count, words = counter(texts)\n",
    "text = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fontは自分の端末にあるものを使用する\n",
    "fpath = r\"C:\\home\\Fonts\\RictyDiminished-for-Powerline-master\\RictyDiminished-Bold.ttf\"\n",
    "wordcloud = WordCloud(background_color=\"white\",font_path=fpath, width=900, height=500).generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x30f61177b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud.to_file(\"./wordcloud_SherlockHolmes.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
