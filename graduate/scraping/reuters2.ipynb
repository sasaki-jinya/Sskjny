{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 日付条件の設定\n",
    "strdt = dt.strptime(\"20180101\", '%Y%m%d')  # 開始日\n",
    "enddt = dt.strptime(\"20191231\", '%Y%m%d')  # 終了日\n",
    "\n",
    "days_num = (enddt - strdt).days + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datelist = []\n",
    "for i in range(days_num):\n",
    "    datelist.append(strdt + timedelta(days=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "address=[]\n",
    "for d in datelist:\n",
    "    url=\"https://www.reuters.com/resources/archive/jp/\"+ d.strftime(\"%Y%m%d\")+\".html\"\n",
    "    address.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile(r\"<[^>]*?>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def makefile(what,filename):\n",
    "    with open(filename,\"wb\") as f3:\n",
    "        pickle.dump(what,f3)\n",
    "def readfile(filename):\n",
    "    with open(filename,\"rb\") as f4:\n",
    "        ans=pickle.load(f4)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = address[0]\n",
    "html = requests.get(url)\n",
    "html.encoding = 'shift-jis'\n",
    "soup = BeautifulSoup(html.text, 'html.parser')\n",
    "url2=soup.find_all(\"body\")\n",
    "url3=url2[0].find_all(\"div\",{\"class\":\"headlineMed\"})\n",
    "result = []\n",
    "for word in url3:\n",
    "    string=p.sub(\"\",str(word))\n",
    "    result.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "URL = pd.DataFrame(index=[],columns=[])\n",
    "texts=dict()\n",
    "n=0\n",
    "for url in address:\n",
    "    if url[-13:-5] in texts:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            for i in range(0,len(url)):\n",
    "                html = requests.get(url)\n",
    "                html.encoding = 'utf-8'\n",
    "                soup = BeautifulSoup(html.text, 'html.parser')\n",
    "                url2=soup.find_all(\"body\")\n",
    "                url3=url2[0].find_all(\"div\",{\"class\":\"headlineMed\"})\n",
    "                #link = url3[i].find(\"a\")\n",
    "                #tmp_se = pd.Series( [url[-13:-5], link.get('href')])\n",
    "                #URL = URL.append( tmp_se, ignore_index=True )\n",
    "                result = []\n",
    "            for word in url3:\n",
    "                string=p.sub(\"\",str(word))\n",
    "                result.append(string)\n",
    "            texts[url[-13:-5]]=result\n",
    "        except:\n",
    "            texts[url[-13:-5]]=[]\n",
    "        n+=1\n",
    "        if n%100==0:\n",
    "            print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = pd.read_csv('URL2.csv')\n",
    "URL = URL.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180101</td>\n",
       "      <td>http://JP.reuters.com/article/idJP201801010100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180101</td>\n",
       "      <td>http://JP.reuters.com/article/idJP201801010100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180101</td>\n",
       "      <td>http://JP.reuters.com/article/idJP201801010100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180101</td>\n",
       "      <td>http://JP.reuters.com/article/usa-potus-idJPKB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180101</td>\n",
       "      <td>http://JP.reuters.com/article/global-poy-stori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86267</th>\n",
       "      <td>20191209</td>\n",
       "      <td>http://JP.reuters.com/article/idJP201912100100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86268</th>\n",
       "      <td>20191209</td>\n",
       "      <td>http://JP.reuters.com/article/idJPL4N28K1UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86269</th>\n",
       "      <td>20191209</td>\n",
       "      <td>http://JP.reuters.com/article/idJP201912100100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86270</th>\n",
       "      <td>20191209</td>\n",
       "      <td>http://JP.reuters.com/article/%E5%BE%93%E6%A5%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86271</th>\n",
       "      <td>20191209</td>\n",
       "      <td>http://JP.reuters.com/article/idJP201912100100...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                                                  1\n",
       "0      20180101  http://JP.reuters.com/article/idJP201801010100...\n",
       "1      20180101  http://JP.reuters.com/article/idJP201801010100...\n",
       "2      20180101  http://JP.reuters.com/article/idJP201801010100...\n",
       "3      20180101  http://JP.reuters.com/article/usa-potus-idJPKB...\n",
       "4      20180101  http://JP.reuters.com/article/global-poy-stori...\n",
       "...         ...                                                ...\n",
       "86267  20191209  http://JP.reuters.com/article/idJP201912100100...\n",
       "86268  20191209        http://JP.reuters.com/article/idJPL4N28K1UA\n",
       "86269  20191209  http://JP.reuters.com/article/idJP201912100100...\n",
       "86270  20191209  http://JP.reuters.com/article/%E5%BE%93%E6%A5%...\n",
       "86271  20191209  http://JP.reuters.com/article/idJP201912100100...\n",
       "\n",
       "[86272 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE = pd.DataFrame(list(texts.items()),columns=['date', 'TITLEs'])\n",
    "title = pd.DataFrame(index=[],columns=['date', 'TITLE'])\n",
    "\n",
    "for i in range(0,len(TITLE['TITLEs'])):\n",
    "    for l in range(0,len(TITLE['TITLEs'][i])):\n",
    "        tmp_se = pd.Series( [TITLE['date'][i], TITLE['TITLEs'][i][l]], index=title.columns )\n",
    "        title = title.append( tmp_se, ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180101</td>\n",
       "      <td>イランデモ、死者計１３人に 11:38午後 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180101</td>\n",
       "      <td>Ａ東京、琉球が勝つ 11:14午後 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180101</td>\n",
       "      <td>香港民主派が元日デモ 9:22午後 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180101</td>\n",
       "      <td>写真が語る2017年：物議を呼んだ米大統領就任式の全景写真 6:56午後 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180101</td>\n",
       "      <td>写真が語る2017年：ロヒンギャ難民女性、決死の脱出 6:55午後 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176621</th>\n",
       "      <td>20191209</td>\n",
       "      <td>Breakingviews TV: PG&amp;amp;E pays up 2:52午前 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176622</th>\n",
       "      <td>20191209</td>\n",
       "      <td>M&amp;amp;A Monday in healthcare: Merck, Sanofi, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176623</th>\n",
       "      <td>20191209</td>\n",
       "      <td>South African activist crowned Miss Universe 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176624</th>\n",
       "      <td>20191209</td>\n",
       "      <td>Just Eat takeover battle hots up 1:10午前 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176625</th>\n",
       "      <td>20191209</td>\n",
       "      <td>In Ghana, oil makes one fortune, breaks anothe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176626 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                              TITLE\n",
       "0       20180101                          イランデモ、死者計１３人に 11:38午後 UTC\n",
       "1       20180101                              Ａ東京、琉球が勝つ 11:14午後 UTC\n",
       "2       20180101                              香港民主派が元日デモ 9:22午後 UTC\n",
       "3       20180101           写真が語る2017年：物議を呼んだ米大統領就任式の全景写真 6:56午後 UTC\n",
       "4       20180101              写真が語る2017年：ロヒンギャ難民女性、決死の脱出 6:55午後 UTC\n",
       "...          ...                                                ...\n",
       "176621  20191209      Breakingviews TV: PG&amp;E pays up 2:52午前 UTC\n",
       "176622  20191209  M&amp;A Monday in healthcare: Merck, Sanofi, U...\n",
       "176623  20191209  South African activist crowned Miss Universe 2...\n",
       "176624  20191209        Just Eat takeover battle hots up 1:10午前 UTC\n",
       "176625  20191209  In Ghana, oil makes one fortune, breaks anothe...\n",
       "\n",
       "[176626 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "title.to_csv('TITLE-split2018-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.DataFrame(index=[],columns=['date', 'NEWS'])\n",
    "\n",
    "for i in range(0,len(URL)):\n",
    "    html = requests.get(URL['1'][i])\n",
    "    html.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    url2=soup.find_all(\"body\")\n",
    "    url3=url2[0].find_all(\"div\",{\"class\":\"headlineMed\"})\n",
    "    url4 = soup.find(class_=\"Paragraph-paragraph-2Bgue ArticleBody-para-TD_9x\")\n",
    "    try:\n",
    "        tmp_se = pd.Series( [URL['0'][i], url4.get_text()], index=news.columns )\n",
    "        news = news.append( tmp_se, ignore_index=True )\n",
    "    except AttributeError as e:\n",
    "        tmp_se = pd.Series( [URL['0'][i], np.nan], index=news.columns )\n",
    "        news = news.append( tmp_se, ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.to_csv('NEWS-split2018-2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL['NEWS'] = news['NEWS']\n",
    "URL = URL.rename(columns={0: 'date',1: 'URL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL.to_csv('URL2.csv')\n",
    "#URL.to_csv('URL2.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
